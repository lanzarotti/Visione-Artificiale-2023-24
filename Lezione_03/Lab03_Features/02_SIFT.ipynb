{"cells":[{"cell_type":"markdown","metadata":{"id":"kiM3Lk6Hs-Rr"},"source":["# <font color='green'><b> SIFT operator </b></font>\n","\n","\n","### Credits: Hands-on Image Processing with Python, Chapter 7 - Author: Sandipan Dey\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ▶️ Base dir setup\n","import os, sys\n","\n","# check if hosted (Google VM) or running on local server\n","if 'google.colab' in sys.modules:\n","  #@markdown Google Drive root folder - hosted by Google VM (adapt to your local paths)\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=False)\n","  base_dir = 'CV/' #@param {type: \"string\"}\n","  base_dir  = os.path.join('/content/drive/MyDrive/', base_dir)\n","  #!pip install pillow  --upgrade\n","  img_dir = 'data/img/'\n","  vid_dir = 'data/video/'\n","  out_dir = 'output/'\n","  \n","  # move to base_dir \n","  os.chdir(base_dir)\n","else:\n","  #@markdown Path to local folder on PC (adapt to your local paths)\n","  img_dir = '../data/img/'\n","  out_dir = '../data/output/'\n","\n"," \n","\n","print(\"Current dir:\", os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1667555026728,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"lPg-3D3qFBXb","outputId":"7acb58d0-5859-40c1-dc78-d213c2f460be"},"outputs":[],"source":["import numpy as np\n","import cv2 \n","import os\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from scipy import ndimage\n","from scipy.spatial import distance\n","from scipy.spatial import distance_matrix\n","import pickle\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage.io import imread\n","from skimage.color import rgb2gray\n","from skimage import img_as_float, img_as_ubyte\n","\n","cv2.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"elapsed":3257,"status":"ok","timestamp":1667555029980,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"lw1PKVLIAqPe","outputId":"5e562296-5d2e-401e-eb5d-cb5c5c9a27b3"},"outputs":[],"source":["# load an example image \n","img = imread(img_dir + 'monalisa.jpg')# 'flowers.png') #'flowers.jpg')  \n","gray = img_as_ubyte(rgb2gray(img))\n","\n","# show image\n","plt.figure(figsize=(6,6))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YDlspb8H8CuG"},"source":["## <font color='green'><b>SIFT in OpenCV</b></font>\n","\n","\n","So now let’s see SIFT functionalities available in OpenCV. Let’s start with keypoint detection and draw them. First we have to construct a SIFT object. We can pass different parameters to it which are optional and they are well explained in docs.\n","\n","https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html\n"]},{"cell_type":"markdown","metadata":{"id":"zkkWoDVSWgPj"},"source":["**1. create the SIFT object:**\n"," \n","`sift = cv2.SIFT_create()` https://docs.opencv.org/4.4.0/d7/d60/classcv_1_1SIFT.html\n","\n","It has several parameters, but interesting to us:\n","\n","\n","- *nfeatures:*\tThe number of best features to retain (if 0, it returns all the kp it found). The features are ranked by their scores (measured in SIFT algorithm as the local contrast)\n","- *nOctaveLayers:*\tThe number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.\n","\n","- *contrastThreshold:*\tThe contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n","- *edgeThreshold:*\tThe threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold. The larger the edgeThreshold, the less features are filtered out (more features are retained).\n","\n","- *sigma:*\tThe sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":332,"status":"ok","timestamp":1667555385988,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"kTvsZN298MrB"},"outputs":[],"source":["#DEFAULT PARAMETERS VALUES (EQUIVALENT TO CALL sift = cv2.SIFT_create() ):\n","sift = cv2.SIFT_create(nfeatures = 0, nOctaveLayers = 3, contrastThreshold = 0.1, edgeThreshold = 10, sigma = 2)\t "]},{"cell_type":"markdown","metadata":{"id":"kFho0jc_e237"},"source":["**2. Keypoint detection**\n","\n","`kp = sift.detect(gray,None)`\n","\n","`kp` is the list of the detected keypoints, eqch one with the field; \n","- *pt*:\tx & y coordinates of the keypoint\n","\n","- *size*:\tkeypoint diameter\n","\n","- *angle*:\tkeypoint orientation\n","\n","- *response*:\tkeypoint detector response on the keypoint (that is, strength of the keypoint)\n","\n","- *octave*:\tpyramid octave in which the keypoint has been detected\n","\n","- *class_id*:\tobject id"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":207,"status":"ok","timestamp":1667555352335,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"Efpo0HC7r4D1"},"outputs":[],"source":["def print_KP_info(kp, i):\n","  print('Keypoint coordinates: '+ str(kp[i].pt)) \n","  print('Keypoint size: '+ str(kp[i].size))  \n","  print('Keypoint orientation: '+ str(kp[i].angle))  \n","  print('Keypoint response: '+ str(kp[i].response))   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1667555354101,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"GCz-nFWfWauM","outputId":"fd2147a4-5c66-4265-ba72-8fc60460e1e6"},"outputs":[],"source":["#detection\n","kp = sift.detect(gray, None)\n","print('Detected KP: '+ str(len(kp)));\n","\n","KP_i= 0\n","print_KP_info(kp, KP_i)"]},{"cell_type":"markdown","metadata":{},"source":["##### <font color='green'><b>EXERCISE 1: </b></font>\n","Modify the contrastThreshold, the edgeThreshold, and the sigma parameters, and observe the variation in keypoint detection"]},{"cell_type":"markdown","metadata":{"id":"oQKoAeF1vmsX"},"source":["##### <font color='green'><b>EXERCISE 2: </b></font>\n"," \n","Given the list of keypoint, detect the one with the strongest response, and print all the corresponding information using the function `print_KP_info(kp, i)`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1667555359723,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"RF5MqFqbgw00","outputId":"cd44e810-0794-495d-f490-ceedb484cef2"},"outputs":[],"source":["#SOLUTION 1 TO EX 2\n","\n","#detect the keypoint with the strongest response\n","max_response = float('-Inf')\n","max_pos = -1;\n","\n","for i in range(len(kp)):\n","  val = kp[i].response;\n","  if val > max_response:\n","      max_response = val;\n","      max_pos = i;\n","\n","print_KP_info(kp, max_pos)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1667555362208,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"7Jje3KYjsmY3","outputId":"933ac26c-c78a-4eb1-c8af-dd6a146dffcb"},"outputs":[],"source":["#SOLUTION 2 TO EX 2 (BETTER)\n","val = [kp[i].response for i in range(len(kp))];\n","kp_max_resp = np.argmax(val)\n","\n","print_KP_info(kp, kp_max_resp)"]},{"cell_type":"markdown","metadata":{"id":"D_9X3-sX-8MA"},"source":["##### <font color='green'><b>EXERCISE 3: </b></font>\n"," \n","Given the list of keypoint, detect the one with the largest size, and print all the corresponding information using the function `print_KP_info(kp, i)`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1667555364596,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"9K9GxDpf_EbB","outputId":"128670e1-16cc-434e-aca3-9be57fa7b26b"},"outputs":[],"source":["#SOLUTION TO EX 3\n"," \n","val= [kp[i].size for i in range(len(kp))];\n","kp_max_size = np.argmax(val)\n","\n","print_KP_info(kp, kp_max_size)"]},{"cell_type":"markdown","metadata":{"id":"21hVvMT5uyBQ"},"source":["**3. Keypoint descriptor**\n","\n","`keypoints, des = sift.compute(image, keypoints)`\n"," \n","Parameters:\n","- *image*:\tImage.\n","- *keypoints*:\t[List] Input collection of keypoints. Keypoints for which a descriptor cannot be computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint with several dominant orientations (for each orientation).\n","- *descriptors*:\t[array of array] Computed descriptors. In the second variant of the method descriptors[i] are descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the descriptor for keypoint j-th keypoint.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1667555367526,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"dcjqvV__hRIU","outputId":"bbca61c7-3401-4174-8b13-c25f0d341e0e"},"outputs":[],"source":["# compute the keypoint description \n","kp, des = sift.compute(gray, kp)\n","\n","print(\"Descrpitor dimension: \" + str(np.squeeze(des[0].shape)))\n","print(des[0])\n","plt.plot(des[0].flatten())\n","\n","#OR\n","#detection and description in one step\n","kp, des = sift.detectAndCompute(gray,None);\n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"elapsed":964,"status":"ok","timestamp":1667555370891,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"M_Frl-kZ3nCh","outputId":"5fbac412-28a3-4201-c791-41a908a89982"},"outputs":[],"source":["#draw the keypoints on an image\n","imgKP=cv2.drawKeypoints(gray,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","#img=cv2.drawKeypoints(gray,kp,img) #simple visualization\n","\n","plt.figure(figsize=(30,10))\n","plt.imshow(imgKP, cmap='gray', vmin=0, vmax=255)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qneWGH_ozdeq"},"source":["##### <font color='green'><b>EXERCISE 4: </b></font>\n"," \n","Given the keypoint with the maximum response (keypoint: 'kp_max_resp') plot only it using opportunely the function cv2.drawKeypoints.\n","do the same for the kp with max size\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"elapsed":1259,"status":"ok","timestamp":1667387322814,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-60},"id":"_8rYL9eWzc_a","outputId":"aac5608a-4d16-4a72-dbe7-078f07eeffc0"},"outputs":[],"source":["#SOLUTION TO EX 4\n","\n","imgKP_strongest = cv2.drawKeypoints(gray,[kp[kp_max_resp]],img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","#imgKP_strongest = cv2.drawKeypoints(gray,[kp[kp_max_resp]],None,color=(0,255,0))\n","plt.figure(figsize=(20,10))\n","plt.imshow(imgKP_strongest)\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNe081lFjTA34w+y1zNEzcz","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
