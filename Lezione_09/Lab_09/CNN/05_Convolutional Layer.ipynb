{"cells":[{"cell_type":"markdown","metadata":{"id":"SnOl-LTp3H29"},"source":["# Convolutions for Images"]},{"cell_type":"markdown","metadata":{"id":"YjV6nW5d3H3G","origin_pos":0},"source":["Now that we understand how convolutional layers work in theory,\n","we are ready to see how they work in practice.\n","Building on our motivation of convolutional neural networks\n","as efficient architectures for exploring structure in image data,\n","we stick with **images** as our running example."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_rszN863H3J","origin_pos":2,"tab":["pytorch"]},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"markdown","metadata":{"id":"8fKSSzOY4DiD"},"source":["# Implementation of two-dimensional Cross-correlation Operation\n"," - Though the proper name is *cross-correlation*, it is commonly called *convolution*\n","\n","We want to write a `corr2d` function implementing this operation.  \n","Needed elements:\n"," - input tensor `X` (a greyscale image) with shape: $n_h\\times n_w$\n"," - kernel tensor `K` for the convolution, with window: $k_h \\times k_w$\n","   * of course its shape must fit within the image\n"," - $\\Rightarrow$ output tensor `Y` with shape: $(n_h-k_h+1) \\times (n_w-k_w+1)$\n"," - The formula representing the cross-correlation between two matrices $X$ and $K$ is easily deducible from the class explanation:\n"," $$\n"," Y[i,j] = \\sum_s \\sum_t X[s,t]\\cdot K[s+i,t+j]\n"," $$\n"," where the multi-index $(s,t)$ runs over the admissible domain, namely the shape of `Y`."]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[],"id":"UMAgLY113H3L","origin_pos":3,"tab":["pytorch"]},"outputs":[],"source":["def corr2d(X, K):\n","    \"\"\"Compute 2D cross-correlation.\"\"\"\n","    h, w = K.shape\n","    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n","    return Y"]},{"cell_type":"markdown","metadata":{"id":"aT-oVLDH3H3M","origin_pos":5},"source":["Example: let us construct an input tensor `X` and a kernel tensor `K`\n","to validate the cross-correlation operation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1696256508223,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"GrJrt25g3H3N","origin_pos":6,"outputId":"1cbc4e19-3ece-44d4-a197-de49083951d0","tab":["pytorch"]},"outputs":[{"data":{"text/plain":["tensor([[19., 25.],\n","        [37., 43.]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"]},{"cell_type":"markdown","metadata":{"id":"IZ3oFRSI5Rwl"},"source":["# Modules\n","\n","We learned that `nn.Sequential` is a container of layers that are **chained** in cascade.\n","\n","There is a more general and flexible container: a *PyTorch module*, namely `nn.Module` class (not to be confused with the concept of module=library in Python)\n","\n","- PyTorch module can contain other layers and modules as well, i.e. modules can be **nested** in a complicate manner\n","  - a `nn.Module` can be just one layer\n","- `nn.Sequential` is a subclass of `nn.Module`\n","  * it can be a sequence of modules\n","- price to pay for flexibility of `nn.Module`: writing more code\n","  * we are required to define a sublass implementing (the constructor `__init__` and) the `foward()` method\n","  * when a network is used in *forward computation*, the `forward()` method of the class is called\n","    - for `nn.Sequential` PyTorch suitably wires outputs/inputs of the chained layers automatically\n","    - while for a `nn.Module` instance the `forward()` method must be **implemented manually** by the programmer\n","- PyTorch module can be used to implement a *block*, which loosely stands for common group/structure of layers that occurs several times to build up the whole architecture, like in certain modern Deep NN architectures"]},{"cell_type":"markdown","metadata":{"id":"SA7PWVDM3H3P","origin_pos":7},"source":["## Convolutional Layers\n","\n","We have the `corr2d` function implementing the 2D convolution.\n","\n","This is enough for constructing a **convolutional layer**\n","- need to suitably define a subclass of PyTorch module\n","- `nn.Parameter` allows to define the intrinsic parameters of the layer, eg. kernel's weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XS3O8wMN3H3R","origin_pos":9,"tab":["pytorch"]},"outputs":[],"source":["class Conv2D(nn.Module): # Conv2D inherits from nn.Module class\n","    # constructor: we need to initialize Conv2D object using the superclass' constructor first\n","    def __init__(self, kernel_size):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.rand(kernel_size))\n","        self.bias = nn.Parameter(torch.zeros(1)) # not much useful in this specific example, but convolutional layers may have additive bias\n","\n","    # forward() method needed in order to implement network's forward computation\n","    def forward(self, x):\n","        return corr2d(x, self.weight) + self.bias"]},{"cell_type":"markdown","metadata":{"id":"9Es0wSQS3H3S"},"source":["In\n","$h \\times w$ convolution\n","or a $h \\times w$ convolution kernel,\n","the height and width of the convolution kernel are $h$ and $w$, respectively.\n","We also refer to\n","a convolutional layer with a $h \\times w$\n","convolution kernel simply as a $h \\times w$ convolutional layer."]},{"cell_type":"markdown","metadata":{"id":"dYHB6-TP3H3T","origin_pos":11},"source":["## Elementary convolutional layer implementation: Object Edge Detection in Images\n","Let us detect the edge of an object in a \"synthetic image\"\n","by finding the **location of the pixel change**.\n","\n","1. construct a $6\\times 8$ pixel image: middle 4 columns' values are 0=black and the rest are 1=white"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1696256508223,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"LalSkUb23H3U","origin_pos":12,"outputId":"e2ed84ef-fd9b-45cb-98f6-f1f6ec345913","tab":["pytorch"]},"outputs":[{"data":{"text/plain":["tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X = torch.ones((6, 8))\n","X[:, 2:6] = 0\n","X"]},{"cell_type":"markdown","metadata":{"id":"lFQY9Wfa3H3V","origin_pos":14},"source":["2. construct a  $1 \\times 2$ kernel `K`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNuYSXsT3H3W","origin_pos":15,"tab":["pytorch"]},"outputs":[],"source":["K = torch.tensor([[1.0, -1.0]])"]},{"cell_type":"markdown","metadata":{"id":"JVIcwdFu3H3V"},"source":["It behaves as elementary vertical **edge detector**: when performing the cross-correlation operation with the input...\n","- if the **horizontally adjacent elements** are the **same**,\n","the output is 0\n","- otherwise, the output is $\\neq 0$\n"]},{"cell_type":"markdown","metadata":{"id":"YXwf4YvK3H3W"},"source":["3. perform cross-correlation\n","- edge from white to black will yield 1\n","- edge from black to white will yield -1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1696256508224,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"B6VCzcO63H3X","origin_pos":17,"outputId":"a48f62a1-8159-4613-8c3d-8cb224570c7d","tab":["pytorch"]},"outputs":[{"data":{"text/plain":["tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["Y = corr2d(X, K)\n","Y"]},{"cell_type":"markdown","metadata":{"id":"IGqkQBpD3H3X","origin_pos":18},"source":["Does this particular convolutional kernel detect **only vertical** edges in an image?\n"," - it should be clear from the evident directionality\n"," - by transposing the image: surely the edge turns to horizontal\n","   * then try applying the same kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1696256508224,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"FispXzZd3H3Y","origin_pos":19,"outputId":"d54f266a-f084-49cf-9994-d96f66c177a7","tab":["pytorch"]},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["corr2d(X.t(), K)"]},{"cell_type":"markdown","metadata":{"id":"R6Rb1ed-G3UF"},"source":["This kernel simply calculated the difference between two adjacent entries: in numerical mathematics we would say that it calculates the *finite difference* (not far from the numerical approximation of a first-order directional derivative)"]},{"cell_type":"markdown","metadata":{"id":"EbEx3LRY3H3Y","origin_pos":20},"source":["## Using built-in Convolutional Layer: learn a kernel\n","We had the synthetic image `X`, the given kernel `K`, and then calculated the output `Y`\n","\n","**Goal**: let us try to learn the kernel for vertical edge detection, based on examples: (`X`, `Y`)\n","\n","1. construct a convolutional layer\n","2. initialize the kernel randomly\n","  - PyTorch has a default method for randomly initializing the parameters in convolutional (and linear) layers. You can read the details here: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n","3. compute the error wrt the known edges\n","4. update the kernel using the gradient\n"]},{"cell_type":"markdown","metadata":{"id":"dhwyxicX3H3Z"},"source":["Instead of manually implementing a **2D convolutional layer**\n"," - PyTorch's built-in class `nn.Conv2d`\n","   * arguments: # input channels, # output channels, kernel size, stride (default: 1), padding (default: 0), bias (default: True), ...  \n","   https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n","   * images as input to such 2D convolutional layer: 4-dimensional tensor with shape (batch size, # channels, height, width)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1696256508224,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"Dm1xzeNa3H3a","origin_pos":22,"outputId":"e6323135-467b-43ae-fd24-a8851b08770e","tab":["pytorch"]},"outputs":[{"name":"stdout","output_type":"stream","text":["batch 2, loss 13.581\n","batch 4, loss 4.422\n","batch 6, loss 1.620\n","batch 8, loss 0.632\n","batch 10, loss 0.253\n"]}],"source":["# Construct a 2D convolutional layer: 1 input and output channel, 1x2 kernel\n","# For the sake of simplicity, we cancel the bias here\n","conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n","\n","# 1 example per batch\n","# 1 channel in the images\n","# 6x8 images\n","X = X.reshape((1, 1, 6, 8))\n","Y = Y.reshape((1, 1, 6, 7))\n","\n","# This loop manually iterates in the gradient descent method, step size = 0.03\n","for i in range(10):\n","    Y_hat = conv2d(X)\n","    l = (Y_hat - Y) ** 2\n","    conv2d.zero_grad()\n","    l.sum().backward() # This calls the backpropagation, calculating the gradient(s) only\n","    # Then update the kernel weights\n","    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n","    if (i + 1) % 2 == 0:\n","        print(f'batch {i + 1}, loss {l.sum():.3f}')"]},{"cell_type":"markdown","metadata":{"id":"kXip-WRz3H3a","origin_pos":24},"source":["Note that the error has dropped to a small value after 10 iterations. Now we will take a look at the kernel tensor we learned.\n"]},{"cell_type":"markdown","metadata":{"id":"zrDrq4vz3H3b"},"source":["- Learnt kernel weights:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1696256508225,"user":{"displayName":"Jianyi Lin","userId":"16729686391709555871"},"user_tz":-120},"id":"O2YvWBuM3H3b","origin_pos":26,"outputId":"7114d879-42e3-4137-e02c-2d240f623a10","tab":["pytorch"]},"outputs":[{"data":{"text/plain":["tensor([[ 1.0403, -0.9371]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["conv2d.weight.data.reshape((1, 2))"]},{"cell_type":"markdown","metadata":{"id":"jkUg8vDz3H3b","origin_pos":28},"source":["Indeed, the learned kernel tensor is remarkably close\n","to the kernel tensor `K` we defined earlier.\n","\n","\n","## Feature Map and Receptive Field\n","*Feature map* of the 2D convolution: is the result of the 2D convolution of an image with a kernel\n","\n","*Receptive field* of **one** entry in the feature map: the patch in the input of the convolutional layer that is used for calculating that entry\n"," - clearly: shape of a receptive field = shape of the kernel\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Kmi5DHp63H3c","origin_pos":30,"tab":["pytorch"]},"source":["## Summary\n","\n","* The core computation of a two-dimensional convolutional layer is a two-dimensional cross-correlation operation. In its simplest form, this performs a cross-correlation operation on the two-dimensional input data and the kernel, and then adds a bias.\n","* We can design a kernel to detect edges in images.\n","* We can learn the kernel's parameters from data.\n","* With kernels learned from data, the outputs of convolutional layers remain unaffected regardless of such layers' performed operations (either strict convolution or cross-correlation).\n","* When any element in a feature map needs a larger receptive field to detect broader features on the input, a deeper network can be considered."]},{"cell_type":"markdown","metadata":{"id":"43s7_n0U3H3d"},"source":["## Exercises\n","\n","1. Construct an image `X` with diagonal edges.\n","    1. What happens if you apply the kernel `K` in this section to it?\n","    1. What happens if you transpose `X`?\n","    1. What happens if you transpose `K`?\n","1. How do you represent a cross-correlation operation as a matrix multiplication by changing the input and kernel tensors?\n","1. Design some kernels manually.\n","    1. What is the form of a kernel for the (\"discretize\" version of) second derivative?\n","    1. What is the kernel for (the \"discrete\" version of) an integral?\n","    1. What is the minimum size of a kernel to obtain a (\"discrete\" version of the) derivative of order *d*?"]},{"cell_type":"markdown","metadata":{"id":"9Vh-YwKpoUqA"},"source":["## Solutions below\n","\n","1. Construct an image `X` with diagonal edges.\n","    1. What happens if you apply the kernel `K` in this section to it?\n","\n","    It detects the diagonal edges\n","    1. What happens if you transpose `X`?\n","\n","    Nothing changes\n","    1. What happens if you transpose `K`?\n","\n","    Nothing changes\n","1. How do you represent a cross-correlation operation as a matrix multiplication by changing the input and kernel tensors?\n","\n","  Vectorize $K$ into columns of a new matrix $K'$ and build a matrix $X'$ whose columns are the vectorized patches of $X$ having the dimension of $K$. Then compute the matrix product $X'K'$, whose entries will be the resulting convolution feature map in a certain order.\n","1. Design some kernels manually.\n","    1. What is the form of a kernel for the (\"discretize\" version of) second derivative?\n","\n","    See 2nd order differences: https://en.wikipedia.org/wiki/Finite_difference\n","    1. What is the kernel for (the \"discrete\" version of) an integral?\n","\n","    The answer is simple for integrals of one-variable functions; extending to double integrals is conceptually feasible but technically challanging. See Trapezoid Rule for numerically approximating a (single) integral. Assume that the values in the vector $X$ are values sampled from a function $f$ at some points.\n","    1. What is the minimum size of a kernel to obtain a (\"discrete\" version of the) derivative of order *d*?\n","\n","    See higher order differences: https://en.wikipedia.org/wiki/Finite_difference"]}],"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
