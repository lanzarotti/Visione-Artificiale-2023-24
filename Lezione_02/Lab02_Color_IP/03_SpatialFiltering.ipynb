{"cells":[{"cell_type":"markdown","metadata":{"id":"OBHZhHpPS7sy"},"source":["# <font color='green'><b> Spatial Filtering </b></font>\n","\n","\n","### Credits: Hands-on Image Processing with Python, Chapter 2 & 4 - Author: Sandipan Dey\n"]},{"cell_type":"markdown","metadata":{"id":"1dDETfZsuinH"},"source":["**Image Smoothing**\n","\n","*Goal*\n","\n","Learn to:\n","- Blur images with various low pass filters\n","- Apply custom-made filters to images (2D convolution)\n","\n","**Image Sharpening**\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[" \n","## <font color='green'><b>Base Dir setup</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ▶️ Base dir setup\n","import os, sys\n","\n","# check if hosted (Google VM) or running on local server\n","if 'google.colab' in sys.modules:\n","  #@markdown Google Drive root folder - hosted by Google VM (adapt to your local paths)\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=False)\n","  base_dir = 'CV/' #@param {type: \"string\"}\n","  base_dir  = os.path.join('/content/drive/MyDrive/', base_dir)\n","  #MODIFY THESE PATHS TO POINT TO YOUR IMAGES\n","  img_dir = 'data/img/'\n","  vid_dir = 'data/video/'\n","  out_dir = 'output/'\n","  \n","  # move to base_dir \n","  os.chdir(base_dir)\n","else:\n","  #MODIFY THESE PATHS TO POINT TO YOUR IMAGES\n","  img_dir = '../data/img/'\n","  out_dir = '../data/output/'\n","\n","print(\"Current dir:\", os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"d9V5zPG0mVFd"},"source":["## <font color='green'><b>Import libraries</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":464,"status":"ok","timestamp":1666023244661,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"_fRmza_muHpY"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","from mpl_toolkits.mplot3d import Axes3D\n","from scipy.stats import multivariate_normal\n","import plotly.express as px\n","from plotly.subplots import make_subplots       \n","import math\n","from skimage.io import imread\n","from skimage.color import rgb2gray\n","from skimage import img_as_float,img_as_ubyte, exposure\n"," "]},{"cell_type":"markdown","metadata":{"id":"srr2xcxWmbUm"},"source":["## <font color='green'><b>Load an Image</b></font>\n"]},{"cell_type":"markdown","metadata":{},"source":["### In line"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO\n","\n","# 0. import the functions you need that are not already imported\n"," \n","# #1. load the image 'gabbiano.jpg' (using the skimage library)\n"," \n","#2. plot the img in a figure with 3 row and 2 columns\n"," \n","#3. convert to gray scale \n","\n","#4. compute the histogram of the gray scale image\n"," \n","#5. plot the histogram of the gray scale image\n"," \n","\n","#6. Apply the contrast stretching to the rgb image \n","# Set the limits of the contrast stretching to 5 and 95 respectively\n","\n","#7. plot the RGB histogram of the contrasted image \n"," \n","#8. equalize the image with the CLAHE method\n"," \n","\n","#9. plot the histogram of the equalized image\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1666023284048,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"KHmc6eCRuOsE","outputId":"a1517506-b4ac-4f6b-b511-d9d96e8f3a69"},"outputs":[],"source":["#SOLUTION\n","\n","# 0. import the functions you need that are not already imported\n","from skimage.color import rgb2gray\n","from skimage import img_as_float,img_as_ubyte, exposure\n","\n","# 1. load the image 'gabbiano.jpg' (using the skimage library)\n","img = imread(img_dir + 'gabbiano.jpg')\n","\n","#2. plot the img in a figure with 3 row and 2 columns\n","plt.figure(figsize=(10,4))\n","plt.subplot(3,2,1)\n","plt.imshow(img)\n","\n","#3. convert to gray scale\n","gray = img_as_ubyte( rgb2gray(img))\n","\n","#4. compute the histogram of the gray scale image\n","hist, _ = np.histogram(gray.flatten(), 256, [0,255])\n","\n","#5. plot the histogram of the gray scale image\n","plt.subplot(3,2,2)\n","plt.plot(hist)\n","plt.ylabel('gray frequency');\n","plt.xlabel('gray levels');\n","plt.title('Histograms')\n","plt.xlim([0,256])\n","\n","#6. Apply the contrast stretching to the rgb image \n","# Set the limits of the contrast stretching to 5 and 95 respectively\n","pmin = np.percentile(img, 5)\n","pmax = np.percentile(img, 95)\n","print(pmin, pmax)\n","\n","img_rescale = exposure.rescale_intensity(img, (pmin, pmax))\n","plt.subplot(3,2,3)\n","plt.imshow(img_rescale)\n","\n","#7. plot the RGB histogram of the contrasted image \n","plt.subplot(3,2,4) \n","for i, col in enumerate(['r', 'g', 'b']):\n","    \n","    hist, _ = np.histogram(img[:,:,i].flatten(), 256, [0,256])\n","    plt.plot(hist, color = col, label= col)\n","    plt.xlim([0, 256])\n","\n","#8. equalize the image with the CLAHE method\n","img_eq = exposure.equalize_adapthist(img, clip_limit=0.1) #equalize_hist, equalize_adapthist\n","plt.subplot(3,2,5)\n","plt.imshow(img_eq)\n","\n","\n","#9. plot the histogram of the equalized image\n","plt.subplot(3,2,6)\n","plt.hist(img_as_ubyte( rgb2gray(img_eq)).flatten(), bins=256, range=(0, 255)); #calculating histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666023286296,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"WvdPN5O1uUSx","outputId":"d53656fc-b71e-461e-aa88-685aa1718286"},"outputs":[],"source":["img = imread(img_dir + 'bebe.jpg')\n","gray = img_as_ubyte(rgb2gray(img))\n","Height, Width, Channels = img.shape\n","print(Height, Width, Channels)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666023297259,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"lIhtQDINEKrr"},"outputs":[],"source":["def multiPlots(images, titles= [], nCols = 2):\n","\n","  '''multiPlots funtion allows to plot a list of images organized on nCols, with possible titles'''\n","\n","  nImg =len(images)\n","  nRows = math.ceil(nImg/nCols) \n","  f = plt.figure(figsize=(15,5*nRows))\n","\n","  for n, image in enumerate(images): \n","    row = int(n/nCols)+1\n","    col = n%nCols+1\n","    ax = f.add_subplot(nRows, nCols, n+1)\n","    ax.imshow(image, cmap='gray')   \n","    plt.axis('off')\n","    if titles:\n","      plt.title(titles[n]) \n","  "]},{"cell_type":"markdown","metadata":{"id":"Qdu8_vzTqAvu"},"source":["## <font color='green'><b>Smoothing with 2D Convolution</b></font>"]},{"cell_type":"markdown","metadata":{"id":"T05o4ufqmfbP"},"source":["### <font color='green'><b>Smoothing with *Opencv* </b></font>\n","\n","The filtering function of Opencv works both on color and gray images\n"]},{"cell_type":"markdown","metadata":{"id":"pdDjrw7zBxm3"},"source":["##### <font color='green'><b> **1.   Draw your kernel** </b></font>  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":1286,"status":"ok","timestamp":1666023344205,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ARpffwyuBvCa","outputId":"3f60fd2f-7f11-4b58-edad-50e3ba10653e"},"outputs":[],"source":["kernel = np.ones((5,5),np.float32)/25\n","dst = cv2.filter2D(img,-1,kernel) #https://www.tutorialspoint.com/opencv/opencv_filter2d.htm\n","# the parameter \"-1\" means that we want \"dst\" maintains the data type of img.\n","images = []\n","images.append(img)\n","images.append(dst)\n"," \n","titles = ['Original', 'Blurred Box filter']\n","multiPlots(images, titles)"]},{"cell_type":"markdown","metadata":{"id":"Ukt0ynG5XYXC"},"source":["##### <font color='green'><b>EXERCISE 1: </b></font>\n"," \n","- Draw a smoothing kernel 3x3 s.t. \n","\n","$K = \\frac{1}{n} \\left[ \\begin{matrix}\n","1 & 2 & 1 \\\\\n","2 & 3 & 2 \\\\\n","1 & 2 & 1 \\\\\n","\\end{matrix} \\right] $\n","\n","\n","fixing opportunely $n$.  \n","\n","- Apply it on the gray image and compare it with the box filter of the same size. \n","- Which one behaves better?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 1\n","\n","#1.draw the required kernels (box and weighted)\n"," \n","#2. apply the produced kernels to \"img\" obtaining \"dstBox\", and \"dstWeight\"\n"," \n","\n","# 3. [GIVEN] show with the function multiplots:\n","# - the orignal image, \n","# - the one filtered with the box filter\n","# - the one filtered with the weight filter\n"," \n","images = []\n","images.append(img)\n","images.append(dstBox)\n","images.append(dstWeight)\n","\n","titles = ['Original', 'Blurred Box filter', 'Blurred Weight filter']\n","multiPlots(images, titles, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"elapsed":1542,"status":"ok","timestamp":1666023358704,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"q_sCRq3AX4NX","outputId":"4063e4cc-10c7-4bde-b03e-b93c74979c86"},"outputs":[],"source":["#SOLUTION EX 1\n","\n","#1.draw the required kernels (box and weighted)\n","kernelBox = np.ones((3,3),np.float32)/9\n","\n","\n","kernelWeight = np.array([[1, 2, 1], [2, 3 ,2], [1, 2 ,1]], np.float32)\n","kernelWeight = kernelWeight/ np.sum(kernelWeight) #Normalization\n","\n","#2. apply the produced kernels to \"img\" obtaining \"dstBox\", and \"dstWeight\"\n","dstBox = cv2.filter2D(img,-1,kernelBox) #https://www.tutorialspoint.com/opencv/opencv_filter2d.htm\n","dstWeight = cv2.filter2D(img,-1,kernelWeight) #https://www.tutorialspoint.com/opencv/opencv_filter2d.htm\n","\n","#3. [GIVEN] show with the function multiplots:\n","# - the orignal image, \n","# - the one filtered with the box filter\n","# - the one filtered with the weight filter\n","\n","images = []\n","images.append(img)\n","images.append(dstBox)\n","images.append(dstWeight)\n","\n","titles = ['Original', 'Blurred Box filter', 'Blurred Weight filter']\n","multiPlots(images, titles, 3)\n"]},{"cell_type":"markdown","metadata":{"id":"dopSSELYwuqR"},"source":["##### <font color='green'><b> **2. Box Filtering**</b></font>  \n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":1117,"status":"ok","timestamp":1666023364254,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"cLr4gm5IwsgX","outputId":"ffa10a32-6555-4ee7-ebf4-8621b457065f"},"outputs":[],"source":["blur = cv2.blur(img,(5,5))\n","\n","#Visualization\n","images = []\n","images.append(img)\n","images.append(blur)\n"," \n","titles = ['Original', 'Blurred Box filter']\n","multiPlots(images, titles)\n"]},{"cell_type":"markdown","metadata":{"id":"0YyIquxxw9Ps"},"source":["##### <font color='green'><b> **3. Gaussian Filtering**</b></font>  \n","\n","If you want, you can create a Gaussian kernel with the function, `cv2.getGaussianKernel()`, then you can use the `cv2.filter2D()` function, otherwise use `cv2.GaussianBlur()`\n"," "]},{"cell_type":"markdown","metadata":{"id":"GImqbi76EAA_"},"source":["\n","- function to plot Gaussian filter"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":664,"status":"ok","timestamp":1666023370029,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"x9gy4dCnEAjA"},"outputs":[],"source":["def gaussPlot(winSize, sigmaVal):\n","  x, y = np.mgrid[-1*winSize:winSize:30j, -1*winSize:winSize:30j]\n","\n","  # Need an (N, 2) array of (x, y) pairs.\n","  xy = np.column_stack([x.flat, y.flat])\n","\n","  mu = np.array([0.0, 0.0])\n","  sigma = np.array([sigmaVal, sigmaVal])\n","  covariance = np.diag(sigma**2)\n","\n","  z = multivariate_normal.pdf(xy, mean=mu, cov=covariance)\n","\n","  # Reshape back to a (30, 30) grid.\n","  z = z.reshape(x.shape)\n","  fig = plt.figure()\n","  ax = fig.add_subplot(111, projection='3d')\n","  ax.plot_surface(x,y,z)\n","  #ax.plot_wireframe(x,y,z)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZahQSgswGmLz"},"source":["- Gaussian filter definition and application"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"executionInfo":{"elapsed":2410,"status":"ok","timestamp":1666023374782,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"XgQUM-i_xA7g","outputId":"22d50fd3-2303-4a10-d216-31546a67510d"},"outputs":[],"source":["sigmaVal = 1.0\n","winSize = np.uint8(np.round(sigmaVal*3))+1\n","if winSize % 2 == 0: #check: size must be odd\n","  winSize = winSize +1\n","\n","gaussPlot(winSize, sigmaVal)\n","blur = cv2.GaussianBlur(img,(winSize,winSize), sigmaVal)\n","\n","#Visualization\n","images = []\n","images.append(img)\n","images.append(dst)\n"," \n","titles = ['Original', 'Blurred with Gaussian filter']\n","multiPlots(images, titles)\n"," "]},{"cell_type":"markdown","metadata":{"id":"Z9-YhaauIpuY"},"source":["##### <font color='green'><b>-  EXERCISE 2: </b></font>\n","\n","Compare the blurring with box filtering and with gaussian filters incrementing the side of the box filtering (e.g. 5,9,11) and the sigma (e.g. 1,3,5). Which one introduces more aberrations?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 2\n","\n","#1. Compute and plot the images filtered with a box filter of side 5,9,11\n"," \n","\n","#2. Compute and plot the images filtered with a Gaussia filter with sigma 1,3,5\n"," \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#SOLUTION EX 2\n","\n","#1. Compute and plot the images filtered with a box filter of side 5,9,11\n","for i,b in enumerate([5,9,11]):\n","    blur = cv2.blur(img,(b,b))\n","    plt.subplot(2,3,i+1)\n","    plt.imshow(blur)\n","    plt.axis('off')\n","    plt.title(f'Box of side: {b}')\n","\n","#2. Compute and plot the images filtered with a Gaussia filter with sigma 1,3,5\n","for i,s in enumerate([1,3,5]):\n","    w = np.uint8(np.round(s*3))+1 #winsize\n","    if w % 2 == 0: #check: size must be odd\n","        w += 1\n","    blur = cv2.GaussianBlur(img,(w,w), s)\n","    plt.subplot(2,3,4+i)\n","    plt.imshow(blur)\n","    plt.axis('off')\n","    plt.title(f'Gauss.  of sigma: {s}')\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"Rl74BXVyFllN"},"source":["### <font color='gray'><b>Smoothing with *Scipy*  </b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"XMrcF-iono67"},"source":["#### For gray scale images\n"," \n","\n","- use the function `signal.convolve2d()` or, specifically for gaussian filter, `gaussian_filter()`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":2689,"status":"ok","timestamp":1666023383661,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ce0eRCzEFkQJ","outputId":"df39957a-6fb5-4ccd-e30b-9c23ba5365da"},"outputs":[],"source":["from scipy import ndimage, misc, signal \n","from scipy.ndimage import gaussian_filter\n","\n","im = rgb2gray(imread(img_dir + 'cameraman.jpg')) \n","print(im.shape, type(im), im.dtype, np.max(im))\n","\n","blur_box_kernel = np.ones((3,3)) / 9\n","\n","im_blurredBox = signal.convolve2d(im, blur_box_kernel)\n","im_blurredGauss = gaussian_filter(im, sigma=1)\n","\n","\n","#Visualization\n","images = []\n","images.append(im)\n","images.append(im_blurredBox)\n","images.append(im_blurredGauss)\n","\n"," \n","titles = ['Original', 'Box Blurred', 'Gauss Blurred ']\n","multiPlots(images, titles, 3)\n"]},{"cell_type":"markdown","metadata":{"id":"PBhzbiUuIYHP"},"source":["#### For color images\n","\n","- use  `signal.convolve2d()` again\n","or, easier:\n","\n","- `ndimage.convolve()` \n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":579},"executionInfo":{"elapsed":2264,"status":"ok","timestamp":1665648801420,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"7ESVb842IW77","outputId":"fc6389ea-19c5-43dc-8517-a02304dbdb01"},"outputs":[],"source":["from skimage import img_as_float, img_as_ubyte\n","\n","im = img_as_float(imread(img_dir + 'tajmahal.jpg')) \n","#print(im.dtype, np.max(im), im.shape)\n","\n","im_blurredGauss = gaussian_filter(im, sigma=1)\n","\n","blur_box_kernel = np.ones((3,3)) /9\n","im_blurredBox = np.ones(im.shape) \n","\n","\n","for i in range(3):\n","  im_blurredBox[...,i] = signal.convolve2d(im[...,i], blur_box_kernel, mode='same', boundary=\"symm\")\n","\n","\n","blur_kernel = blur_box_kernel.reshape((3, 3, 1)) ##NB: must be 3x3x1 NOT 3x3 \n","im_blurredBox2 = np.clip(ndimage.convolve(im, blur_kernel, mode='nearest'), 0,1)\n","\n","\n","#Visualization\n","images = []\n","images.append(im)\n","images.append(im_blurredGauss)\n","images.append(im_blurredBox)\n","images.append(im_blurredBox2)\n","\n","\n","titles = ['Original', 'Gauss Blurred ', 'Box Blurred', 'Box Blurred']\n","multiPlots(images, titles, )\n"," "]},{"cell_type":"markdown","metadata":{"id":"S04mCmbgIgl5"},"source":["### <font color='gray'><b>Smoothing with *Skimage* </b></font>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"elapsed":2618,"status":"ok","timestamp":1665649089853,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"jgZrjgIZIm9Z","outputId":"c1bb355a-47eb-41ec-8df0-628c8a396574"},"outputs":[],"source":["from skimage import img_as_float, img_as_ubyte\n","from skimage.filters import gaussian\n","\n","im = img_as_float(imread(img_dir + 'victoria_memorial.png'))  \n","#print(im.dtype, np.max(im)) \n","\n","gauss_blurred = np.clip(gaussian(im, sigma= 1), 0,1)\n","\n","\n","#Visualization\n","images = []\n","images.append(im)\n"," \n","images.append(gauss_blurred)\n","\n","titles = ['Original', 'Gauss Blurred ']\n","multiPlots(images, titles, 2)\n"," "]},{"cell_type":"markdown","metadata":{"id":"44NwBiXvxz-_"},"source":["## <font color='green'><b>Bilateral Filtering</b></font>\n"," \n"," "]},{"cell_type":"markdown","metadata":{"id":"kZw2gdMP3p6F"},"source":["\n","\n","https://www.geeksforgeeks.org/python-bilateral-filtering/\n","\n","As we noted, the filters we presented earlier tend to blur edges. This is not the case for the bilateral filter, cv2.bilateralFilter(), which was defined for, and is highly effective at noise removal while preserving edges. But the operation is slower compared to other filters. We already saw that a Gaussian filter takes the neighborhood around the pixel and finds its Gaussian weighted average. This Gaussian filter is a function of space alone, that is, nearby pixels are considered while filtering. It does not consider whether pixels have almost the same intensity value and does not consider whether the pixel lies on an edge or not. The resulting effect is that Gaussian filters tend to blur edges, which is undesirable.\n","\n","The bilateral filter also uses a Gaussian filter in the space domain, but it also uses one more (multiplicative) Gaussian filter component which is a function of pixel intensity differences. The Gaussian function of space makes sure that only pixels are ‘spatial neighbors’ are considered for filtering, while the Gaussian component applied in the intensity domain (a Gaussian function of intensity differences) ensures that only those pixels with intensities similar to that of the central pixel (‘intensity neighbors’) are included to compute the blurred intensity value. As a result, this method preserves edges, since for pixels lying near edges, neighboring pixels placed on the other side of the edge, and therefore exhibiting large intensity variations when compared to the central pixel, will not be included for blurring.\n","\n","The sample below demonstrates the use of bilateral filtering (For details on arguments, see the OpenCV docs).\n","\n","\n","\n","- d: Diameter of each pixel neighborhood.\n","- sigmaColor: Value of $\\sigma$ in the color space. The greater the value, the colors farther to each other will start to get mixed.\n","- sigmaSpace: Value of $\\sigma$ in the coordinate space. The greater its value, the more further pixels will mix together, given that their colors lie within the sigmaColor range.\n","\n","Details about the bilateral filtering can be found [here](http://people.csail.mit.edu/sparis/bf_course/)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":552},"executionInfo":{"elapsed":4205,"status":"ok","timestamp":1666023638468,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"gy05wpdxx3aS","outputId":"eba7d0f4-8a46-4696-ef0b-630129672c0a"},"outputs":[],"source":["from skimage import img_as_float32\n","from skimage.restoration import denoise_bilateral\n","from skimage.util import random_noise \n","\n","img = img_as_float32(imread(img_dir + 'cycle.jpg'))\n","sigma = 0.1\n"," \n","#Add noise to an image\n","noisyGauss = np.uint8(random_noise(img, mode='gaussian', var=sigma**2)*255)  \n","\n","# - Bilateral filtering opencv (RECOMMENDED)\n","bilateral_Img = cv2.bilateralFilter(img,d=6,sigmaColor=5, sigmaSpace=1) \n","bilateral_Gauss = cv2.bilateralFilter(noisyGauss,6,5,1) #we can omit the parameter name, and put juts the value in the expected order\n","\n","#- Bilateral filtering skimage (TOO SLOW! with different scale range for the parameters)\n","#bilateral_Img = denoise_bilateral(img, sigma_color=0.1, sigma_spatial=15, multichannel=True)                \n","#bilateral_Gauss = denoise_bilateral(noisyGauss, sigma_color=0.1, sigma_spatial=20, multichannel=True)  \n"," \n","# - Gaussian filtering\n","img_blurred = cv2.GaussianBlur(img,(3,3), 1)\n","gauss_blurred = cv2.GaussianBlur(noisyGauss,(3,3), 1)\n","\n","# - Visualization\n","images = []\n","images.append(img)\n","images.append(bilateral_Img)\n","images.append(img_blurred)\n","images.append(noisyGauss)\n","images.append(bilateral_Gauss)\n","images.append(gauss_blurred)\n","\n","titles = ['Original', 'Bilateral filter', 'Gaussian filtering', 'Gauss Noise', 'Bilateral filter', 'Gaussian filtering',]\n","multiPlots(images, titles,3)\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"f_1kfkn5xOga"},"source":["## <font color='green'><b>Median Filtering</b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"BQmzZpnXrYf0"},"source":["### <font color='green'><b>Median Filtering using *Opencv*</b></font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nGkWTzMCdHrj"},"source":["Here, the function cv2.medianBlur() computes the median of all the pixels under the kernel window and the central pixel is replaced with this median value. This is highly effective in removing salt-and-pepper noise. One interesting thing to note is that, in the Gaussian and box filters, the filtered value for the central element can be a value which may not exist in the original image. However this is not the case in median filtering, since the central element is always replaced by some pixel value in the image. This reduces the noise effectively. The kernel size must be a positive odd integer.\n","\n","In this demo, we add a 50% noise to our original image and use a median filter. Check the result:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"elapsed":1112,"status":"ok","timestamp":1665651223391,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"VFOKEDWJT5BW","outputId":"3694eb9f-2462-4d3a-89e1-6dfe8db08291"},"outputs":[],"source":["from skimage import img_as_float, img_as_ubyte\n","\n","orig = imread(img_dir + 'lena.jpg')\n","noisy = np.copy(orig)\n","\n","# add salt-and-pepper noise to the input image\n","noise = np.random.random(orig.shape)\n","noisy[noise > 0.9] = 255\n","noisy[noise < 0.1] = 0\n"," \n","\n","#Visualization\n","images = []\n","images.append(orig)\n","images.append(noisy)\n","  \n","titles = ['Original', 'S&P noise, Color']\n","multiPlots(images, titles, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665651226772,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ZPruvZxxxULK","outputId":"b2c294bc-a6e2-4c73-b297-bb6c9a683e0e"},"outputs":[],"source":["kernelSize=5\n","median = cv2.medianBlur(noisy, kernelSize)\n","\n","#Visualization\n","images = []\n","images.append(noisy) \n","images.append(median) \n","titles = ['S&P noise', 'Median. kernel size: '+ str(kernelSize)]\n","multiPlots(images, titles)\n"," "]},{"cell_type":"markdown","metadata":{"id":"pYYrMkvWUcrA"},"source":["### <font color='gray'><b>Median Filtering using *Scipy*, a generalization </b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"0KANnGm7URMX"},"source":["- *Scipy* has the function `ndimage.precentile_filter()` that is a generalization of the median filter. \n","\n","  - The median filter is obtained setting the parameter `percentile=50`\n","  - changing it we obtain other rank filters (e.g. min , max)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"elapsed":1561,"status":"ok","timestamp":1665651499762,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"n48GXXA7SaxZ","outputId":"da226856-fc65-4a59-d873-4423162b112c"},"outputs":[],"source":["from scipy import ndimage, misc, signal \n","\n","images = []\n","titles = []\n","\n","for i, k in enumerate(range(5,20,5)):\n","  filtered = ndimage.percentile_filter(noisy, percentile=50, size=(k,k,1))\n","  images.append(filtered) \n","  titles.append(' 50 perc., ' + str(k) + 'x' + str(k) + ' kernel') \n"," \n","multiPlots(images, titles, 3)"]},{"cell_type":"markdown","metadata":{"id":"chIVRGE7rpB6"},"source":["### <font color='gray'><b>Median Filtering using *Skimage*</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"elapsed":785,"status":"ok","timestamp":1665563062429,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ntXcZp3csVEv","outputId":"9082f5b3-e801-45b2-be85-29cd778eab29"},"outputs":[],"source":["from skimage.filters import median\n","from skimage.morphology import disk\n","\n","noisy_gray = rgb2gray(noisy)\n","kernelSize = 3 \n","med = median(noisy_gray, disk(kernelSize))\n","\n","#Visualization\n","images = []\n","images.append(noisy_gray) \n","images.append(med) \n","titles = ['S&P noise, Gray', 'Median. kernel size: '+ str(kernelSize)]\n","multiPlots(images, titles)\n"," "]},{"cell_type":"markdown","metadata":{"id":"xO6ljqEZx7ZV"},"source":["#### <font color='green'><b>-  EXERCISE 3: </b></font>\n","   \n","- given the images with gaussian noise created above (`noisyGauss`), compare the effect of blurring via Gaussian, median and bilateral filters.\n","\n","- Do the same on the image with SP noise `noisySP`.\n","Which filter works better in the two cases?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 3\n"," \n"," \n"," \n"," \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7317,"status":"ok","timestamp":1666024078178,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"eYwCHO9jnmA6","outputId":"877356be-2629-4e1d-c9de-52013892f627"},"outputs":[],"source":["#SOLUTION EX 3\n","\n","#ADD NOISE to an image\n","perc_SP_noise = 0.1\n","noisySP = np.uint8(random_noise(img, mode='s&p', amount = perc_SP_noise)*255)\n","\n","#FILTER THE NOISY IMAGES\n","gauss_G = cv2.GaussianBlur(noisyGauss,(3,3), 1)\n","bilateral_Gauss = cv2.bilateralFilter(noisyGauss,6,5,1)  \n","med_G = cv2.medianBlur(noisyGauss, 5)\n"," \n","gauss_SP = cv2.GaussianBlur(noisySP,(3,3), 1)\n","med_SP = cv2.medianBlur(noisySP, 5)\n","bilateral_SP = cv2.bilateralFilter(noisyGauss,6,5,1)\n","\n","#VISUALIZATION\n","images = []\n","images.append(noisyGauss) \n","images.append(bilateral_Gauss)\n","images.append(gauss_G) \n","images.append(med_G)\n","\n","images.append(noisySP) \n","images.append(bilateral_SP)\n","images.append(gauss_SP) \n","images.append(med_SP)\n","\n","titles = ['Gaussian Noise', 'Bilateral filter', 'Gaussian filter', 'Median filter',\n","          'SP Noise', 'Bilateral filter', 'Gaussian filter', 'Median filter']\n","multiPlots(images, titles)\n"," "]},{"cell_type":"markdown","metadata":{"id":"fXhfDmE_XGhn"},"source":["## <font color='green'><b>Sharpen filter with 2D Convolution</b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"Qc3petgWs4Qe"},"source":["### <font color='green'><b>Sharpen filter with *Opencv*</b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"scRz4T49Ux4R"},"source":["##### **1. Draw your kernel**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":1876,"status":"ok","timestamp":1666018635671,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"hc_vxaKeXJ32","outputId":"aa2b18d2-b494-49b1-9f5a-6fece6fd4ece"},"outputs":[],"source":["kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]],np.float32)\n","dst = cv2.filter2D(img,-1,kernel) #https://www.tutorialspoint.com/opencv/opencv_filter2d.htm\n","\n","\n","#Visualization\n","images = []\n","images.append(img) \n","images.append(dst) \n","\n","titles = ['Original', 'Sharpening']\n","multiPlots(images, titles)\n"," "]},{"cell_type":"markdown","metadata":{"id":"jtfnqkAdXtRF"},"source":["#### <font color='green'><b>EXERCISE 4 </b></font>\n"," \n","\n","Define a function `highBoost(img, a)` that given an image and the value `a`, apply the high boost filtering and return the filtered image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 4\n","def highBoost(img, a):\n","\n","  #1. define the central value\n"," \n","  #2.define the normalization factor\n","  \n","  #3. draw the kernel\n","   \n","  #4. apply the kernel to \"img\"\n","  \n","  #5.return the filtered image\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666018647235,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"2b3bWdzYo1rG"},"outputs":[],"source":["#SOLUTION EX 4\n","def highBoost(img, a):\n","\n","  #1. define the central value\n","  w= 9*a -1\n","  \n","  #2.define the normalization factor\n","  sumWeights = -1*8 + w\n","  \n","  #3. draw the kernel\n","  kernel = (1/max(1, sumWeights))*np.array([[-1,-1,-1], [-1,w,-1], [-1,-1,-1]],np.float32)\n","  \n","  #4. apply the kernel to \"img\"\n","  dst = cv2.filter2D(img,-1,kernel) \n","  \n","  #5.return the filtered image\n","  return dst"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":1709,"status":"ok","timestamp":1666018660905,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"2APSLaiTXsym","outputId":"8351625f-385a-493b-b5c9-c8cb34098be9"},"outputs":[],"source":["a= 1.5\n","out= highBoost(img, a)\n","\n","#Visualization\n","images = []\n","images.append(img) \n","images.append(out) \n","titles = ['Original', 'HighBoost with parameter a:' + str(a)]\n","multiPlots(images, titles) "]},{"cell_type":"markdown","metadata":{"id":"MfyxYD7St9tu"},"source":["### <font color='gray'><b>Sharpen filter with *scipy*</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"elapsed":553,"status":"ok","timestamp":1665564026479,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"gBIYNgRGt3Gy","outputId":"9dfbebb7-95e3-4200-ee27-e5f999a13fec"},"outputs":[],"source":["grayImg = rgb2gray(img)\n","sharp_kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n","im_sharp =  signal.convolve2d(grayImg, sharp_kernel)\n","im_sharp = im_sharp / np.max(im_sharp)\n","\n","#Visualization\n","images = []\n","images.append(grayImg) \n","images.append(im_sharp) \n","titles = ['Original', 'Sharpen']\n","multiPlots(images, titles) \n"," "]},{"cell_type":"markdown","metadata":{"id":"wtHHpZWquJIC"},"source":["### <font color='gray'><b>Sharpen filter with *skimage*</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"elapsed":2559,"status":"ok","timestamp":1665564199101,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"6wMuQ80wuZZR","outputId":"ec276531-6abc-4228-f1db-b068da09363d"},"outputs":[],"source":["im = img_as_float(imread(img_dir + 'tajmahal.jpg')) \n","\n","sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]).reshape((3, 3, 1))\n","im_sharpen = np.clip(ndimage.convolve(im, sharpen_kernel, mode='nearest'), 0,1)\n","\n","emboss_kernel = np.array(np.array([[-2,-1,0],[-1,1,1],[0,1,2]])).reshape((3, 3, 1))\n","im_emboss = np.clip(ndimage.convolve(im, emboss_kernel, mode='nearest'), 0,1)\n","\n","#Visualization\n","images = []\n","images.append(im) \n","images.append(im_sharpen) \n","images.append(im_emboss) \n","titles = ['Original', 'Sharpen', 'Emboss']\n","multiPlots(images, titles, 3) \n"," \n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAHirvO7aINEAUB4+wtXyE","collapsed_sections":["d9V5zPG0mVFd","srr2xcxWmbUm","T05o4ufqmfbP"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
